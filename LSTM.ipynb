{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOAp0k/jkq9AELYQzK3j43T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyuhsin1999/Fake_Medical_News_Detection_Tool/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn3AHI5sYf95",
        "outputId": "d5617b8b-1e3d-48fd-a1b1-b61f53b90593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Fake_Medical_News_Detection_Tool'...\n",
            "remote: Enumerating objects: 247, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 247 (delta 47), reused 0 (delta 0), pack-reused 160\u001b[K\n",
            "Receiving objects: 100% (247/247), 5.22 MiB | 9.88 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Fake_Medical_News_Detection_Tool\" # Enter repo name\n",
        "git_path = 'https://github.com/changyuhsin1999/Fake_Medical_News_Detection_Tool.git'\n",
        "!git clone \"{git_path}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import torch\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "YgYHkb5CYwBk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv('/content/Fake_Medical_News_Detection_Tool/data/raw_df.csv')\n",
        "tokenizer = Tokenizer(num_words = 3000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True, split = ' ')\n",
        "tokenizer.fit_on_texts(texts = raw_df['full_text'])\n",
        "X = tokenizer.texts_to_sequences(texts = raw_df['full_text'])\n",
        "X = pad_sequences(sequences = X, maxlen = 3000, padding = 'pre')\n",
        "y = raw_df['label'].values"
      ],
      "metadata": {
        "id": "KxuEksDrgP0t"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
      ],
      "metadata": {
        "id": "I_0Rnn1ehN9m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the model\n",
        "lstm_model = Sequential(name = 'lstm_nn_model')\n",
        "lstm_model.add(layer = Embedding(input_dim = 3000, output_dim = 120, name = '1st_layer'))\n",
        "lstm_model.add(layer = LSTM(units = 120, dropout = 0.2, recurrent_dropout = 0.2, name = '2nd_layer'))\n",
        "lstm_model.add(layer = Dropout(rate = 0.5, name = '3rd_layer'))\n",
        "lstm_model.add(layer = Dense(units = 120,  activation = 'relu', name = '4th_layer'))\n",
        "lstm_model.add(layer = Dropout(rate = 0.5, name = '5th_layer'))\n",
        "lstm_model.add(layer = Dense(units = len(set(y)),  activation = 'sigmoid', name = 'output_layer'))\n",
        "# compiling the model\n",
        "lstm_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzVwU9i2dfsL",
        "outputId": "d5761411-54bf-48ee-c1ae-7fb3187a5714"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer 2nd_layer will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_fit = lstm_model.fit(X_train, y_train, epochs = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFoMqiNIeBUV",
        "outputId": "494ac343-5d43-4945-cebc-79d491b34c84"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 1185s 15s/step - loss: 0.0902 - accuracy: 0.9682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (lstm_model.predict(X_test) >= 0.5).astype(\"int\")\n",
        "y_pred = y_pred[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moj2OywsoogV",
        "outputId": "737e72b6-b87b-4ff7-bd12-334ea9999a4e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 17s 877ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_eQUkprpohp",
        "outputId": "9a87015f-d658-4c9e-db57-d5bf47c3a734"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       205\n",
            "           1       0.99      0.99      0.99       432\n",
            "\n",
            "    accuracy                           0.99       637\n",
            "   macro avg       0.98      0.99      0.99       637\n",
            "weighted avg       0.99      0.99      0.99       637\n",
            "\n"
          ]
        }
      ]
    }
  ]
}